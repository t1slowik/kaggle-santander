{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Santander competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general & data analysis imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=pd.read_csv('train.csv')\n",
    "test_dataset=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove dependent variable from train set to have the same structure as test set\n",
    "df_target=train_dataset['target'].copy()\n",
    "df_train=train_dataset.drop(['ID_code','target'], axis=1)\n",
    "df_test=test_dataset.drop('ID_code', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sm = SMOTE(random_state=1)\n",
    "#X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "#X_val, y_val = sm.fit_resample(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training, tuning and evaluation - random search\n",
    "random hyperparameters search, without kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val=train_test_split(df_train.values,df_target.values,test_size=0.15,random_state=1, shuffle=True)\n",
    "X_test=df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgbm parameters values for random search\n",
    "param_grid = dict(\n",
    "         objective =  ['binary'],\n",
    "         learning_rate = np.logspace(-3, -1, num=50, base=10.0),\n",
    "         feature_fraction = np.logspace(-2, -1, num=50, base=10.0),\n",
    "         num_leaves = np.arange(10,30,2),\n",
    "         min_data_in_leaf = np.arange(30,150,50),\n",
    "         bagging_fraction = np.arange(0.3,0.95,0.01),\n",
    "         bagging_freq = np.arange(3, 30, 5),\n",
    "         max_depth = [-1],\n",
    "         boosting_type = ['gbdt'],\n",
    "         metric = ['auc'],\n",
    "         min_sum_hessian_in_leaf = np.logspace(-4, 2, num=50, base=10.0),\n",
    "         n_jobs = [-1],\n",
    "         num_round = [2500]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(param_grid, X_train, X_val, y_train, y_val, iterations):\n",
    "    train_set = lgb.Dataset(X_train, label=y_train)\n",
    "    val_set = lgb.Dataset(X_val, label=y_val)\n",
    "    param_list=list(param_grid.keys())\n",
    "    metrics_list=['ROC_train','ROC_val','ROC_diff']\n",
    "    logging_list=param_list+metrics_list\n",
    "    results=[]\n",
    "    try:\n",
    "        for i in range(iterations):\n",
    "            print(f'iteration {i+1} of {iterations}')\n",
    "            # randomly select parameters\n",
    "            param = dict()\n",
    "            for key in param_grid:\n",
    "                param[key] = np.random.choice(param_grid[key])\n",
    "            print(f'selected params:{param}')\n",
    "            # train the model\n",
    "            clf = lgb.train(param, train_set, valid_sets=[train_set,val_set], verbose_eval=500,early_stopping_rounds = 400)\n",
    "            # calculate & log statistics\n",
    "            y_train_proba=clf.predict(X_train)\n",
    "            y_val_proba=clf.predict(X_val)\n",
    "            param['ROC_train']=roc_auc_score(y_train,y_train_proba)\n",
    "            param['ROC_val']=roc_auc_score(y_val,y_val_proba)\n",
    "            param['ROC_diff']=param['ROC_train']-param['ROC_val']\n",
    "            logging_list\n",
    "            # log results\n",
    "            result_line=[]\n",
    "            # log parameters\n",
    "            for key in logging_list:\n",
    "                result_line.append(param[key])\n",
    "            results.append(result_line)\n",
    "    except(KeyboardInterrupt):\n",
    "        pass\n",
    "    # save results to file\n",
    "    result_df=pd.DataFrame(results, columns=logging_list)\n",
    "    result_df.to_csv('hp_search.csv', index=False)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 of 100\n",
      "selected params:{'objective': 'binary', 'learning_rate': 0.001, 'feature_fraction': 0.08685113737513525, 'num_leaves': 14, 'min_data_in_leaf': 80, 'bagging_fraction': 0.8300000000000005, 'bagging_freq': 23, 'max_depth': -1, 'boosting_type': 'gbdt', 'metric': 'auc', 'min_sum_hessian_in_leaf': 5.963623316594637, 'n_jobs': -1, 'num_round': 2500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\slowito1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:113: UserWarning: Found `num_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "random_search(param_grid, X_train, X_val, y_train, y_val, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training, tuning and evaluation - hyperopt\n",
    " hyperparameters search by hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val=train_test_split(df_train.values,df_target.values,test_size=0.15,random_state=1, shuffle=True)\n",
    "X_test=df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "space= { 'objective': 'binary', \n",
    "         'boosting_type': 'gbdt',\n",
    "         'metric': 'auc',\n",
    "         'learning_rate': hp.loguniform('learning_rate', 1e-2, 1e-1),\n",
    "         'max_depth':  hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n",
    "         'feature_fraction': hp.uniform('feature_fraction',0.01, 0.9),\n",
    "         'bagging_fraction': hp.uniform('bagging_fraction',0.01, 0.9),\n",
    "         'num_leaves': hp.choice('num_leaves', np.arange(10, 40, dtype=int)),\n",
    "         'min_data_in_leaf': hp.choice('min_data_in_leaf', np.arange(30, 150, 10, dtype=int)),\n",
    "         'bagging_freq': hp.choice('bagging_freq', np.arange(3, 10, dtype=int)),\n",
    "         'n_jobs': -1,\n",
    "         'num_round': 2500\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(hp_params):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final training\n",
    "kfold with best found hyperparameters\n",
    "predicted probabilities are mean of predictions from all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating fold 1/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\slowito1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:113: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 400 rounds.\n",
      "[500]\tvalid_0's auc: 0.888485\n",
      "[1000]\tvalid_0's auc: 0.895666\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-c42c06565202>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtrain_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mval_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalid_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalid_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_param\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_set\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0my_probs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfold_n\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mtoc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    211\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1753\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1754\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1755\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1756\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1757\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_param = {'objective': 'binary', 'metric': 'auc', 'learning_rate': 0.03, 'feature_fraction': 0.025,\n",
    "              'num_leaves': 10, 'min_data_in_leaf': 130, 'bagging_fraction': 0.5, 'bagging_freq': 3, \n",
    "              'num_rounds': 4000, 'verbose': 1}\n",
    "        # , 'device': 'gpu', 'gpu_use_dp': False}\n",
    "\n",
    "# predicted probabilities on test set (competition set)\n",
    "y_probs = np.zeros(len(df_test.values))\n",
    "fold_n=3\n",
    "folds = StratifiedKFold(n_splits=fold_n, shuffle=True, random_state=30)\n",
    "for i, (train_index, valid_index) in enumerate(folds.split(df_train,df_target)):\n",
    "    tic=time.time()\n",
    "    print(f'Calculating fold {i+1}/{fold_n}...')\n",
    "    train_set = lgb.Dataset(df_train.iloc[train_index], label=df_target.iloc[train_index])\n",
    "    val_set = lgb.Dataset(df_train.iloc[valid_index], label=df_target.iloc[valid_index])\n",
    "    clf = lgb.train(best_param, train_set, valid_sets=[train_set, val_set], verbose_eval=500,early_stopping_rounds = 400)\n",
    "    y_probs += clf.predict(df_test.values, num_iteration=clf.best_iteration)/fold_n\n",
    "    toc=time.time()\n",
    "    print(f'Fold {i+1} calcutated in {toc-tic}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_val_probs=clf.predict(X_val)\n",
    "#y_val_preds=np.where(y_val_probs>0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc_auc_score(y_val, y_val_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_probs=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09905054, 0.21218829, 0.16893732, ..., 0.00809165, 0.1014492 ,\n",
       "       0.06534386])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\"ID_code\":test_dataset[\"ID_code\"].values})\n",
    "submission_df[\"target\"] = y_probs\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

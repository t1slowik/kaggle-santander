{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Santander competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general & data analysis imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=pd.read_csv('train.csv')\n",
    "test_dataset=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove dependent variable from train set to have the same structure as test set\n",
    "df_target=train_dataset['target'].copy()\n",
    "df_train=train_dataset.drop(['ID_code','target'], axis=1)\n",
    "df_test=test_dataset.drop('ID_code', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sm = SMOTE(random_state=1)\n",
    "#X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "#X_val, y_val = sm.fit_resample(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training, tuning and evaluation - random search\n",
    "random hyperparameters search, without kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val=train_test_split(df_train.values,df_target.values,test_size=0.2,random_state=1, shuffle=True)\n",
    "X_test=df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgbm parameters values for random search\n",
    "param_grid = dict(\n",
    "         objective =  ['binary'],\n",
    "         learning_rate = np.logspace(-3, -1, num=50, base=10.0),\n",
    "         feature_fraction = np.logspace(-2, -1, num=50, base=10.0),\n",
    "         num_leaves = np.arange(10,30,2),\n",
    "         min_data_in_leaf = np.arange(30,150,50),\n",
    "         bagging_fraction = np.arange(0.3,0.95,0.01),\n",
    "         bagging_freq = np.arange(3, 30, 5),\n",
    "         max_depth = [-1],\n",
    "         boosting_type = ['gbdt'],\n",
    "         metric = ['auc'],\n",
    "         min_sum_hessian_in_leaf = np.logspace(-4, 2, num=50, base=10.0),\n",
    "         n_jobs = [-1],\n",
    "         num_round = [2500]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(param_grid, X_train, X_val, y_train, y_val, iterations):\n",
    "    train_set = lgb.Dataset(X_train, label=y_train)\n",
    "    val_set = lgb.Dataset(X_val, label=y_val)\n",
    "    param_list=list(param_grid.keys())\n",
    "    metrics_list=['ROC_train','ROC_val','ROC_diff']\n",
    "    logging_list=param_list+metrics_list\n",
    "    results=[]\n",
    "    try:\n",
    "        for i in range(iterations):\n",
    "            print(f'iteration {i+1} of {iterations}')\n",
    "            # randomly select parameters\n",
    "            param = dict()\n",
    "            for key in param_grid:\n",
    "                param[key] = np.random.choice(param_grid[key])\n",
    "            print(f'selected params:{param}')\n",
    "            # train the model\n",
    "            clf = lgb.train(param, train_set, valid_sets=[train_set,val_set], verbose_eval=500,early_stopping_rounds = 400)\n",
    "            # calculate & log statistics\n",
    "            y_train_proba=clf.predict(X_train)\n",
    "            y_val_proba=clf.predict(X_val)\n",
    "            param['ROC_train']=roc_auc_score(y_train,y_train_proba)\n",
    "            param['ROC_val']=roc_auc_score(y_val,y_val_proba)\n",
    "            param['ROC_diff']=param['ROC_train']-param['ROC_val']\n",
    "            logging_list\n",
    "            # log results\n",
    "            result_line=[]\n",
    "            # log parameters\n",
    "            for key in logging_list:\n",
    "                result_line.append(param[key])\n",
    "            results.append(result_line)\n",
    "    except(KeyboardInterrupt):\n",
    "        pass\n",
    "    # save results to file\n",
    "    result_df=pd.DataFrame(results, columns=logging_list)\n",
    "    result_df.to_csv('hp_search.csv', index=False)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search(param_grid, X_train, X_val, y_train, y_val, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training, tuning and evaluation - hyperopt\n",
    " hyperparameters search by hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val=train_test_split(df_train.values,df_target.values,test_size=0.15,random_state=1, shuffle=True)\n",
    "X_test=df_test.values\n",
    "train_set = lgb.Dataset(X_train, label=y_train)\n",
    "val_set = lgb.Dataset(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space= { 'objective': 'binary', \n",
    "         'boosting_type': 'gbdt',\n",
    "         'metric': 'auc',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.04,\n",
    "         # 'max_depth':hp.quniform('max_depth', 4, 14, 1),\n",
    "         'feature_fraction': hp.uniform('feature_fraction',0.01, 0.2),\n",
    "         'bagging_fraction': hp.uniform('bagging_fraction',0.2, 0.9),\n",
    "         'num_leaves': hp.quniform('num_leaves', 10, 20, 1),\n",
    "         'min_data_in_leaf': hp.quniform('min_data_in_leaf', 75, 85, 1),\n",
    "         'bagging_freq': hp.quniform('bagging_freq', 3, 10, 1),\n",
    "         'n_jobs': -1,\n",
    "         'num_round': 3000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(param):\n",
    "    # print received params\n",
    "    # print(f'received params: {param}')\n",
    "    # convert to integers\n",
    "    integer_params=['max_depth', 'num_leaves', 'min_data_in_leaf', 'bagging_freq']\n",
    "    for p in integer_params:\n",
    "        param[p]=int(param[p])\n",
    "    print(f'corrected params: {param}')\n",
    "    # train clasiffier\n",
    "    clf = lgb.train(param, train_set, valid_sets=[train_set,val_set], verbose_eval=1000,early_stopping_rounds = 400)\n",
    "    # calculate ROC (more is better)\n",
    "    y_val_proba=clf.predict(X_val)\n",
    "    roc=roc_auc_score(y_val,y_val_proba)\n",
    "    # return optimization result (less is better)\n",
    "    return 1-roc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier = fmin(check_model,space,algo=tpe.suggest,max_evals=150)\n",
    "print(best_classifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final training\n",
    "Kfold with best found hyperparameters. Predicted probabilities are mean of predictions from all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating fold 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\slowito1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:113: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 400 rounds.\n",
      "[500]\ttraining's auc: 0.90442\tvalid_1's auc: 0.890074\n",
      "[1000]\ttraining's auc: 0.912202\tvalid_1's auc: 0.896432\n",
      "[1500]\ttraining's auc: 0.917283\tvalid_1's auc: 0.899101\n",
      "[2000]\ttraining's auc: 0.921287\tvalid_1's auc: 0.900481\n",
      "[2500]\ttraining's auc: 0.924929\tvalid_1's auc: 0.901141\n",
      "[3000]\ttraining's auc: 0.927809\tvalid_1's auc: 0.901922\n",
      "[3500]\ttraining's auc: 0.930756\tvalid_1's auc: 0.902281\n",
      "[4000]\ttraining's auc: 0.933523\tvalid_1's auc: 0.902529\n",
      "[4500]\ttraining's auc: 0.936257\tvalid_1's auc: 0.902815\n",
      "[5000]\ttraining's auc: 0.93878\tvalid_1's auc: 0.902951\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's auc: 0.93878\tvalid_1's auc: 0.902951\n",
      "Fold 1 calcutated in 206.73588609695435.\n",
      "Calculating fold 2/4...\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "[500]\ttraining's auc: 0.905695\tvalid_1's auc: 0.883989\n",
      "[1000]\ttraining's auc: 0.914279\tvalid_1's auc: 0.889088\n",
      "[1500]\ttraining's auc: 0.919304\tvalid_1's auc: 0.892481\n",
      "[2000]\ttraining's auc: 0.923219\tvalid_1's auc: 0.894281\n",
      "[2500]\ttraining's auc: 0.926752\tvalid_1's auc: 0.895306\n",
      "[3000]\ttraining's auc: 0.929598\tvalid_1's auc: 0.895646\n",
      "[3500]\ttraining's auc: 0.932387\tvalid_1's auc: 0.895979\n",
      "[4000]\ttraining's auc: 0.935195\tvalid_1's auc: 0.896199\n",
      "[4500]\ttraining's auc: 0.937885\tvalid_1's auc: 0.896485\n",
      "Early stopping, best iteration is:\n",
      "[4433]\ttraining's auc: 0.937561\tvalid_1's auc: 0.896558\n",
      "Fold 2 calcutated in 189.96940803527832.\n",
      "Calculating fold 3/4...\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "[500]\ttraining's auc: 0.905338\tvalid_1's auc: 0.887267\n",
      "[1000]\ttraining's auc: 0.91329\tvalid_1's auc: 0.893929\n",
      "[1500]\ttraining's auc: 0.918022\tvalid_1's auc: 0.896833\n",
      "[2000]\ttraining's auc: 0.92185\tvalid_1's auc: 0.898497\n",
      "[2500]\ttraining's auc: 0.9255\tvalid_1's auc: 0.899294\n",
      "[3000]\ttraining's auc: 0.928295\tvalid_1's auc: 0.899705\n",
      "[3500]\ttraining's auc: 0.931171\tvalid_1's auc: 0.90032\n",
      "[4000]\ttraining's auc: 0.934015\tvalid_1's auc: 0.900561\n",
      "[4500]\ttraining's auc: 0.936675\tvalid_1's auc: 0.900763\n",
      "[5000]\ttraining's auc: 0.939247\tvalid_1's auc: 0.900829\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's auc: 0.939247\tvalid_1's auc: 0.900829\n",
      "Fold 3 calcutated in 190.95565700531006.\n",
      "Calculating fold 4/4...\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "[500]\ttraining's auc: 0.906724\tvalid_1's auc: 0.885604\n",
      "[1000]\ttraining's auc: 0.914074\tvalid_1's auc: 0.892325\n",
      "[1500]\ttraining's auc: 0.918914\tvalid_1's auc: 0.895029\n",
      "[2000]\ttraining's auc: 0.922894\tvalid_1's auc: 0.896516\n",
      "[2500]\ttraining's auc: 0.926503\tvalid_1's auc: 0.897694\n",
      "[3000]\ttraining's auc: 0.929263\tvalid_1's auc: 0.898059\n",
      "[3500]\ttraining's auc: 0.93214\tvalid_1's auc: 0.898427\n",
      "[4000]\ttraining's auc: 0.935027\tvalid_1's auc: 0.898487\n",
      "Early stopping, best iteration is:\n",
      "[3732]\ttraining's auc: 0.933544\tvalid_1's auc: 0.898601\n",
      "Fold 4 calcutated in 198.11019206047058.\n"
     ]
    }
   ],
   "source": [
    "# 0.900 (from random search)\n",
    "best_param = {'objective': 'binary', 'metric': 'auc', 'learning_rate': 0.02, 'feature_fraction': 0.023,\n",
    "              'num_leaves': 10, 'min_data_in_leaf': 80, 'bagging_fraction': 0.46, 'bagging_freq': 18, \n",
    "              'min_sum_hessian_in_leaf': 1.45, 'num_rounds': 5000, 'verbose': 1}\n",
    "fold_n=4\n",
    "\n",
    "# 0.896 (from hyperopt)\n",
    "#best_param = {'objective': 'binary', 'metric': 'auc', 'bagging_fraction': 0.7755883925843395, 'bagging_freq': 4,\n",
    "#              'feature_fraction': 0.11619997622598302, 'min_data_in_leaf': 85, 'num_leaves': 19,\n",
    "#              'learning_rate': 0.04, 'max_depth': -1, 'num_rounds': 5000, 'verbose': 1}\n",
    "#fold_n=5\n",
    "\n",
    "# predicted probabilities on test set (competition set)\n",
    "y_probs = np.zeros(len(df_test.values))\n",
    "folds = StratifiedKFold(n_splits=fold_n, shuffle=True, random_state=30)\n",
    "for i, (train_index, valid_index) in enumerate(folds.split(df_train,df_target)):\n",
    "    tic=time.time()\n",
    "    print(f'Calculating fold {i+1}/{fold_n}...')\n",
    "    train_set = lgb.Dataset(df_train.iloc[train_index], label=df_target.iloc[train_index])\n",
    "    val_set = lgb.Dataset(df_train.iloc[valid_index], label=df_target.iloc[valid_index])\n",
    "    clf = lgb.train(best_param, train_set, valid_sets=[train_set, val_set], verbose_eval=500, early_stopping_rounds = 400)\n",
    "    # y_probs += clf.predict(df_test.values, num_iteration=clf.best_iteration)/fold_n\n",
    "    y_probs += clf.predict(df_test.values)/fold_n\n",
    "    toc=time.time()\n",
    "    print(f'Fold {i+1} calcutated in {toc-tic}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 400 rounds.\n",
      "[500]\ttraining's auc: 0.899538\n",
      "[1000]\ttraining's auc: 0.905339\n",
      "[1500]\ttraining's auc: 0.90874\n",
      "[2000]\ttraining's auc: 0.911266\n",
      "[2500]\ttraining's auc: 0.913613\n",
      "[3000]\ttraining's auc: 0.915054\n",
      "[3500]\ttraining's auc: 0.916634\n",
      "[4000]\ttraining's auc: 0.918196\n",
      "[4500]\ttraining's auc: 0.919637\n",
      "[5000]\ttraining's auc: 0.920892\n",
      "[5500]\ttraining's auc: 0.922118\n",
      "[6000]\ttraining's auc: 0.923209\n",
      "[6500]\ttraining's auc: 0.924424\n",
      "[7000]\ttraining's auc: 0.925567\n",
      "[7500]\ttraining's auc: 0.92667\n",
      "[8000]\ttraining's auc: 0.927826\n",
      "[8500]\ttraining's auc: 0.92888\n",
      "[9000]\ttraining's auc: 0.929924\n",
      "[9500]\ttraining's auc: 0.930953\n",
      "[10000]\ttraining's auc: 0.931979\n",
      "[10500]\ttraining's auc: 0.932979\n",
      "[11000]\ttraining's auc: 0.933961\n",
      "[11500]\ttraining's auc: 0.934974\n",
      "[12000]\ttraining's auc: 0.935964\n",
      "[12500]\ttraining's auc: 0.936964\n",
      "[13000]\ttraining's auc: 0.937965\n",
      "[13500]\ttraining's auc: 0.938943\n",
      "[14000]\ttraining's auc: 0.939914\n",
      "[14500]\ttraining's auc: 0.940877\n",
      "[15000]\ttraining's auc: 0.941836\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[15000]\ttraining's auc: 0.941836\n"
     ]
    }
   ],
   "source": [
    "best_param = {'objective': 'binary', 'metric': 'auc', 'learning_rate': 0.01, 'feature_fraction': 0.023,\n",
    "              'num_leaves': 10, 'min_data_in_leaf': 80, 'bagging_fraction': 0.46, 'bagging_freq': 18, \n",
    "              'min_sum_hessian_in_leaf': 1.45, 'num_rounds': 15000, 'verbose': 1}\n",
    "\n",
    "train_set = lgb.Dataset(df_train.values, label=df_target.values)\n",
    "clf = lgb.train(best_param, train_set, valid_sets=[train_set], verbose_eval=500, early_stopping_rounds = 400)\n",
    "y_probs = clf.predict(df_test.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\"ID_code\":test_dataset[\"ID_code\"].values})\n",
    "submission_df[\"target\"] = y_probs\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
